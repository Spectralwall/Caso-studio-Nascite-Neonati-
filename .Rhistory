#INDICI DI POSIZIONE
#usiamo un dataset pre fatto, ovvero iris
data("iris")
force(iris)
View(iris)
head(iris)
head(iris,5)#mostriamo le prime 5 righe del dataset
head(iris,10)#mostriamo le prime 5 righe del dataset
levels(iris$Species)#vediamo le specie
#estraimano le colonne del dataframe
attach(iris)
View(iris)
#moda
table(Species)
#andiamo ora su variabili quantitative
n = lenght(Petal.Length)
#andiamo ora su variabili quantitative
n = length(Petal.Length)
sort(Petal.Length)
Petal.Length[1]
sort(Petal.Length)
Petal.Length[1]
Petal.Length[0]
sort(Petal.Length)[1]
min(Petal.Length)
max(Petal.Length)
sort(Petal.Length)[n]#alternativa per avere il massimo
#mediana
sort(Petal.Length)[n/2]
#mediana
median(Petal.Length)
sort(Petal.Length)[75]#fatta da me
sort(Petal.Length)[c(75,76)]
#quantili
#la mediana e il secondo quaritle e lo abbiamo gia trovato
#dobbiamo trovare ora il 1 e il 3 quartile
n/4
#quartili
#la mediana e il secondo quaritle e lo abbiamo gia trovato
#dobbiamo trovare ora il 1 e il 3 quartile
sort(Petal.Length)[38]
#mentre per il 3 sara n/4 *3 che dara
n/4*3
#mentre per il 3 sara n/4 *3 che dara
(n/4)*3
#mentre per il 3 sara n/4 *3 che dara 122.5 arrotondato sara 123
sort(Petal.Length)[123]
#la funzione di R è
quantile(Petal.Length)
#mentre per il 3 sara n/4 *3 che dara 112.5 arrotondato sara 113
sort(Petal.Length)[113]
quantile(Petal.Length,c(0,1,0.1))
quantile(Petal.Length,c(0,2,0.1))
quantile(Petal.Length,c(0,150,0.1))
quantile(Petal.Length,seq(0,1,0.1))#cosi troviamo i decili
quantile(Petal.Length,seq(0,1,1))#cosi troviamo i decili
quantile(Petal.Length,seq(0,10,0.1))#cosi troviamo i decili
quantile(Petal.Length,seq(0,1,0.2))#cosi troviamo i decili
quantile(Petal.Length,seq(0,1,0.2))#cosi troviamo i quintili
quantile(Petal.Length,seq(0,1,0.01))#cosi troviamo i percentili
#media
sum(Petal.Length)/n
mean(Petal.Length)
median(Petal.Length)#funzione automatica
mean(Petal.Length)
#dimostriamo che la mediana è molto più forte
x = c(Petal.Length,541,378)
mean(x)
median(x)
#dividiamo in classi e costruiamo la ditribuzione di frequenza in classi
Petal_Length_cl = cut(Petal.Length,seq(0,7,1))
table(Petal_Length_cl)
fi = table(Petal_Length_cl)/n
fi
ni
ni = table(Petal_Length_cl)
ni
Ni = cumsum(Petal_Length_cl)
Ni = cumsum(table(Petal_Length_cl))
Fi = cumsum(table(Petal_Length_cl))/n
dist_freq = as.data.frame(cbind(ni,fi,Ni,Fi))
dist_freq
table(Petal_Length_cl)
#classe modale (classe con più elemenetni)
median(dist_freq$ni)
quantile(dist_freq$ni)
#funzione di R
quantile(Petal.Length)#trova anche min e max
dist_freq
#classe modale (classe con più elemenetni)
median(dist_freq$ni)
median(Petal.Length)#funzione automatica
mean(Petal.Length)
#la mediana
median(dist_freq$ni)
#funzione di R
quantile(Petal.Length)#trova anche min e max
dist_freq
#Media Ponderata
dist_freq$cxi = seq(0,6.5,1)#aggiungi la righa come sequenza che va da 0 a 6.5 di passo 1
dist_freq
#Media Ponderata
dist_freq$cxi = seq(0.5,6.5,1)#aggiungi la righa come sequenza che va da 0 a 6.5 di passo 1
dist_freq
sum(dist_freq$cxi*ni)/n
sum(dist_freq$cxi*dist_freq$ni)/n
weighted.mean(dist_freq$cxi,ni)
install.packages("quantmod")
library(quantmod)
incrementi = quantmod::Delt(cellule)*100
#MEDIA GEOMETRICA
cellule = c(1000,1800,2100,3000,5000)#abbiamo un esempio che mostra il numero di cellule in giorni diversi
incrementi = quantmod::Delt(cellule)*100
incrementi
#facciamo in modo che incrementi sia un vettore
incrementi = [-1,1]
#facciamo in modo che incrementi sia un vettore
incrementi = incrementi[-1,1]
incrementi
geometric_min <- function(vettore){
return(prod(vettore)^(1/length(vettore)))#radice di n del prodotto di tutti i dati
}
geometric_min(incrementi)
mean(incrementi)
#una volta finito usiamo il detach per riattacare le colonne
detach()
#la velocita media di percorrenza di queste 4 velocità (serve la media armonica)
1/speed
#MEDIA ARMONICA
speed <- c(100,80,40,90)#velocita nei vari tratti di strada e noi vogliamo
#la velocita media di percorrenza di queste 4 velocità (serve la media armonica)
1/speed
#la velocita media di percorrenza di queste 4 velocità (serve la media armonica)
1/mean(1/speed)
mean(speed)
return(1/mean(1/vettore))
return(1 / (sum(1/vettore)/length(vettore)))
return(1/(sum(1/y)/length(y)))
return(1/(sum(1/vettore)/length(vettore)))
return(1 / (sum(1/x)/length(x)) )
return(1 / (sum(1/x)/length(x)) )
return(1/(sum(1/x)/length(x)) )
armonic_mean <- function(x){
return(1/(sum(1/x)/length(x)) )
}
return(1/(sum(1/x)/length(x)) )
return(1/(sum(1/x)/length(x)))
armonic_mean <- function(x){
return(1/(sum(1/x)/length(x)))
}
armonic_mean2 <- function(x){
return(1/mean(1/x))
}
#la velocita media di percorrenza di queste 4 velocità (serve la media armonica)
1/mean(1/speed)#abbiamo dovuto scriverla perche non esiste la funzione di R
armonic_mean(speed)
armonic_mean2(speed)
install.packages("Metrics")
library(Metrics)
#ANALISI NASCITE NEONATI
#IMPORT
library(moments)
library(ggplot2)
library(gridExtra)
library(grid)
library(ggthemes)
library(PerformanceAnalytics)
library(knitr)
library(magrittr)
library(corrplot)
library(car)
library(lmtest)
library(sandwich)
library(estimatr)
library(dplyr)
library(skedastic)
library(Metrics)
#FUNZIONI
#Funzione che calcola la moda/classe modale
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
#COEFFIECENTE DI VARIAZIONE
CV <- function(x){
return((sd(x)/mean(x))*100)
}
#INDICE DI ETEROGENEITA DI GINI Normalizzato
G <- function(x){
ni=table(x) #frequenze assolute
fi=ni/length(x)#frequenze relative
fi2 = fi^2 #frequenze relative al quadrato
J = length(table(x)) #tipi di classi che abbiamo
gini = 1-sum(fi2) #G=1-sommatoria di frequenze relative al quadrato
gini_norm = gini/((J-1)/J)
return(gini_norm)
}
#funzione che data una variabile quantitava divisa in classi calcola la distribuzione assoluta
distribuzione_assoluta <- function(x){
n=length(x)
ni=table(x)
fi=table(x)/n
Ni=cumsum(table(x))
Fi=cumsum(table(x))/n
return(as.data.frame(cbind(ni,fi,Ni,Fi)))
}
#funzione che genera una tabella contenente tutti gli indici di una variabile
#indici di posizione, variabilità e forma
analisi.quantitative <- function(x,y,z){
df=as.data.frame(cbind(summary(x)))
colnames(df)<-c(y)
df2=data.frame(summary=c(max(x)-min(x),IQR(x),Mode(x),var(x),
sd(x),CV(x),skewness(x),kurtosis(x)-3))
rownames(df2) <- c("Range","IQR","Mode","Var","SD","CV","Asymmetry","Curtosi")
colnames(df2)<-c(y)
df_all = rbind(df,df2)
png("report.png", height = 24*nrow(df_all), width = 215*ncol(df_all))
grid.table(df_all)
dev.off()
plot=ggplot()+
geom_density(aes(x=x),col="darkblue",fill="lightblue")+
geom_vline(aes(xintercept=mean(x)),
color="red", linetype="dashed", linewidth=1)+
geom_vline(aes(xintercept=quantile(x,seq(0,1,0.25))),
color="green3", linetype="dashed", linewidth=1)+
geom_vline(aes(xintercept=median(x)),
color="orange", linetype="dashed", linewidth=1)+
geom_vline(aes(xintercept=Mode(x)),
color="yellow", linetype="dashed", linewidth=1)+
xlab("Sales")+
ylab("Density")+
labs(title = c(z))+
theme_fivethirtyeight()
print("Distribuzione, Summary, Range, Range Interquantile, Moda, Variaza, Devizione standard, Coefficente di variazione, Assiemtria, Curtosi")
return(
list(
plot,
summary(x),
max(x)-min(x),
IQR(x),
Mode(x),
var(x),
sd(x),
CV(x),
skewness(x),
kurtosis(x)-3
)
)
}
#funzione che fa un analisi compleata delle variabili quantitative
#esegue tabelle di frequenza assoluta, relativa, cumulata e indice di gini
analisi.qualitative <- function(x){
n=length(x)
ni=table(x)
fi=table(x)/n
Ni=cumsum(table(x))
Fi=cumsum(table(x))/n
df=as.data.frame(cbind(ni,fi,Ni,Fi))
png("Frequenze.png", height = 50*nrow(df), width = 100*ncol(df))
grid.table(df)
dev.off()
png("Gini.png", height = 50*nrow(df), width = 50*ncol(df))
grid.table(data.frame(Gini=c(G(x))))
dev.off()
}
#funzione che data una variabile quantitativa e una sequenza di valori
#divide la variabile in classi e stampa un grafico a barre
analisi.classi <- function(x,y){
classi = cut(x,y)#divisa in 7 classi da 1 centimetro l'uno
df_freq = distribuzione_assoluta(classi)
ggplot(data=df_freq, aes(x=reorder(row.names(df_freq), +fi), y=ni,fill=row.names(df_freq))) +
geom_bar(stat="identity")+
labs(title="Distribuzione in classi",
x="Classi",
y="Frequenza")+
theme_fivethirtyeight()+
theme(axis.title = element_text())+
guides(fill=guide_legend(title="Classi"))
}
format(1000, scientific = TRUE)
#import dataset
#se computer portatile
setwd("C:\\Users\\gabri\\Desktop\\PrivateProject\\Caso-studio-Nascite-Neonati-")
neonati <- read.csv("neonati.csv",stringsAsFactors = T)
attach(neonati)
head(neonati)
summary(neonati)
#Analisi variabili
#Anni madre---------------------------------------------------------------------
summary(neonati$Anni.madre)
table(neonati$Anni.madre)#ci sono due valori fuori scala
detach(neonati)
#rimuoviamo dal dataset tutte le registrazioni in cui gli anni della madre sono minori di 12
#di solito la possibilià di rimanere incinete avviene in concomitanza con l'inzio il primo ciclo che è intorno al 12 anno di età
neonati.filtrato <- subset(neonati,Anni.madre>=12)
attach(neonati.filtrato)
#prima di inizare a creare i modelli dividiamo il dataset in training e test set
neonati.filtrato$id <- 1:nrow(neonati.filtrato)
#use 70% of dataset as training set and 30% as test set
train <- neonati.filtrato %>% dplyr::sample_frac(0.95)
test  <- dplyr::anti_join(neonati.filtrato, train, by = 'id')
mod9<- lm(log(Peso)~
N.gravidanze+
log(Gestazione)+
log(Lunghezza)+
log(Cranio)+
Tipo.parto+
Sesso,
data=train)
summary(mod9)
#per valutare sia leverers che outliars abbiamo la distanza di cook
cook<-cooks.distance(mod9)
# Cook's distance
par(mfrow=c(1,1))
plot(mod9, 5, id.n = 5)
plot(mod9, 4, id.n = 5)
max(cook)
#individuiamo valori che hanno distanza di cook molto alta e eliminiamoli
influential <- cook[(cook > (3 * mean(cook, na.rm = TRUE)))]
names_of_influential <- names(influential)
influential
train <- train %>% anti_join(train[names_of_influential,])
mod9<- lm(log(Peso)~
N.gravidanze+
log(Gestazione)+
log(Lunghezza)+
log(Cranio)+
Tipo.parto+
Sesso,
data=train)
summary(mod9)
#togliamo altri outliars
#per valutare sia leverers che outliars abbiamo la distanza di cook
cook<-cooks.distance(mod9)
influential <- cook[(cook > (10 * mean(cook, na.rm = TRUE)))]
names_of_influential <- names(influential)
influential
train <- train %>% anti_join(train[names_of_influential,])
mod9<- lm(log(Peso)~
N.gravidanze+
log(Gestazione)+
log(Lunghezza)+
log(Cranio)+
Tipo.parto+
Sesso,
data=train)
summary(mod9)
#Rieseguiamo i test
#test di normalita --> ipotes di normalita
shapiro.test(residuals(mod9))
#test di Omoschedasticità --> ipotesi di omoschedacita
bptest(mod9)
#test di incorellazione
dwtest(mod9)
#test di Omoschedasticità --> ipotesi di omoschedacita
bptest(mod9)
#proviamo ora a cambiare lo standard error con il robust standard error, per risolvere
coeftest(mod9, vcov = vcovHC(mod9, "HC1"))
#creiamo degli esempi fittizi
testMedian <- data.frame(N.gravidanze = 3,Gestazione=39,Lunghezza=500,Cranio=340,Tipo.parto="Nat",Sesso="F")
testMean <- data.frame(N.gravidanze = 3,Gestazione=39,Lunghezza=494.6958,Cranio=340.0292,Tipo.parto="Nat",Sesso="F")
#facciamo delle predizioni
predMedian = predict(mod9, newdata = testMedian)
predMean = predict(mod9, newdata = testMean)
predictionTest = predict(mod9, newdata = test)
exp(predMedian)
exp(predMean)
#calcoliamo la stima Root Mean Square Error
#che misura l'errore medio eseguito dal modello nel prevedere l'esito di un'osservazione.
rmse(test$Peso, predictionTest)
#calcoliamo la stima Root Mean Square Error
#che misura l'errore medio eseguito dal modello nel prevedere l'esito di un'osservazione.
rmse(test$Peso, predictionTest)
#calcolimao la stima MAE
mae(test$Peso, predictionTest)
rmse <- sqrt(sum((exp(predictionTest) - test$Peso)^2)/length(test$Peso))
c(RMSE = rmse, R2=summary(mod9)$r.squared)
length(test$Peso)
length(predictionTest)
#calcoliamo la stima Root Mean Square Error
#che misura l'errore medio eseguito dal modello nel prevedere l'esito di un'osservazione.
rmse(test$Peso, predictionTest)
#calcoliamo la stima Root Mean Square Error
#che misura l'errore medio eseguito dal modello nel prevedere l'esito di un'osservazione.
rmse(test$Peso, predictionTest)
rmse(test$Peso, exp(predictionTest)
rmse(test$Peso, exp(predictionTest))
rmse(test$Peso, exp(predictionTest))
c(RMSE = rmse, R2=summary(mod9)$r.squared)
#calcolimao la stima MAE
mae(test$Peso, exp(predictionTest))
mod9$df.residual
mod9$coefficients
summary(mod9)
